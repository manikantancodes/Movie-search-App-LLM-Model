{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI\n",
    "import openai\n",
    "import streamlit as st\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your OpenAI API key\n",
    "api_key = 'your api key'\n",
    "openai.api_key = api_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Five Came Back: The Reference Films This collection includes 12 World War II-era propaganda films — many of which are graphic and offensive — discussed in the docuseries \"Five Came Back.\" ['documentation']\n",
      "Rocky When world heavyweight boxing champion, Apollo Creed wants to give an unknown fighter a shot at the title as a publicity stunt, his handlers choose palooka Rocky Balboa, an uneducated collector for a Philadelphia loan shark. Rocky teams up with trainer  Mickey Goldmill to make the most of this once in a lifetime break. ['drama', 'sport']\n",
      "Grease Australian good girl Sandy and greaser Danny fell in love over the summer. But when they unexpectedly discover they're now in the same high school, will they be able to rekindle their romance despite their eccentric friends? ['romance', 'comedy']\n",
      "The Sting A novice con man teams up with an acknowledged master to avenge the murder of a mutual friend by pulling off the ultimate big con and swindling a fortune from a big-time mobster. ['cri\n"
     ]
    }
   ],
   "source": [
    "# Function to load and prepare dataset\n",
    "def load_and_prepare_data(url):\n",
    "    df = pd.read_csv(url)\n",
    "    \n",
    "    # Handle missing values by replacing NaN with empty string\n",
    "    df['title'] = df['title'].fillna('')\n",
    "    df['description'] = df['description'].fillna('')\n",
    "    df['genres'] = df['genres'].fillna('')\n",
    "    \n",
    "    # Combine columns to form a single text column\n",
    "    df['text'] = df['title'] + \" \" + df['description'] + \" \" + df['genres'].astype(str)\n",
    "    \n",
    "    # Join all text data into a single document\n",
    "    doc = \"\\n\".join(df['text'].tolist())\n",
    "    return doc\n",
    "\n",
    "# Example URL - replace with your actual CSV URL\n",
    "url = 'https://raw.githubusercontent.com/datum-oracle/netflix-movie-titles/main/titles.csv'\n",
    "doc = load_and_prepare_data(url)\n",
    "print(doc[:1000])  # Print first 1000 characters of the document to verify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split text into chunks\n",
    "def split_text(doc):\n",
    "    splitter = CharacterTextSplitter(\n",
    "        separator=\"\\n\",\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=100,\n",
    "        length_function=len,\n",
    "    )\n",
    "    texts = splitter.split_text(doc)\n",
    "    return texts\n",
    "\n",
    "# Split the document\n",
    "texts = split_text(doc)\n",
    "print(f'Number of chunks: {len(texts)}')\n",
    "print(texts[:2])  # Print the first two chunks to verify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prepare the vector store\n",
    "def prepare_vector_store(text, api_key):\n",
    "    splitter = CharacterTextSplitter(\n",
    "        separator=\"\\n\",\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=100,\n",
    "        length_function=len\n",
    "    )\n",
    "    texts = splitter.split_text(text)\n",
    "    embed_text = FAISS.from_texts(texts, OpenAIEmbeddings(openai_api_key=api_key))\n",
    "    return embed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load QA chain\n",
    "def load_qa_chain(api_key):\n",
    "    model = load_qa_chain(OpenAI(openai_api_key=api_key), chain_type=\"stuff\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamlit application\n",
    "def main():\n",
    "    st.title(\"Movie QA Application\")\n",
    "    \n",
    "    # Define the URL for the movie dataset\n",
    "    url = 'https://raw.githubusercontent.com/datum-oracle/netflix-movie-titles/main/titles.csv'\n",
    "    \n",
    "    # Load and prepare data\n",
    "    doc = load_and_prepare_data(url)\n",
    "    \n",
    "    # Prepare vector store\n",
    "    embed_text = prepare_vector_store(doc, openai.api_key)\n",
    "    \n",
    "    # Load QA chain\n",
    "    model = load_qa_chain(openai.api_key)\n",
    "    \n",
    "    # User input for query\n",
    "    query = st.text_input(\"Enter your question about movies:\")\n",
    "    \n",
    "    if query:\n",
    "        # Search for relevant documents\n",
    "        my_docs = embed_text.similarity_search(query)\n",
    "        \n",
    "        # Generate an answer\n",
    "        answer = model.run(input_documents=my_docs, question=query)\n",
    "        \n",
    "        st.write(\"Answer:\")\n",
    "        st.write(answer)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
